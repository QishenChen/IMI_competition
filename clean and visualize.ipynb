{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This file is for coding to clean and visualize the data to prepare for the unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "data_abm = pd.read_csv('abm.csv')\n",
    "data_card = pd.read_csv('card.csv')\n",
    "data_eft = pd.read_csv('eft.csv')\n",
    "data_emt = pd.read_csv('emt.csv')\n",
    "data_kyc = pd.read_csv('kyc.csv')\n",
    "data_wire = pd.read_csv('wire.csv')\n",
    "data_kyc_industry_codes = pd.read_csv('kyc_industry_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the dataset\n",
    "## Null value\n",
    "We first count null value each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abm_id              0.000000\n",
      "customer_id         0.000000\n",
      "amount_cad          0.000000\n",
      "debit_credit        0.000000\n",
      "cash_indicator      0.000000\n",
      "country             0.185506\n",
      "province            0.416227\n",
      "city                0.416227\n",
      "transaction_date    0.000000\n",
      "transaction_time    0.000000\n",
      "dtype: float64\n",
      "card_trxn_id         0.000000\n",
      "customer_id          0.000000\n",
      "amount_cad           0.000000\n",
      "debit_credit         0.000000\n",
      "merchant_category    0.173314\n",
      "ecommerce_ind        0.000000\n",
      "country              0.378131\n",
      "province             0.390205\n",
      "city                 0.517976\n",
      "transaction_date     0.000000\n",
      "transaction_time     0.000000\n",
      "dtype: float64\n",
      "eft_id              0.0\n",
      "customer_id         0.0\n",
      "amount_cad          0.0\n",
      "debit_credit        0.0\n",
      "transaction_date    0.0\n",
      "transaction_time    0.0\n",
      "dtype: float64\n",
      "emt_id              0.0\n",
      "customer_id         0.0\n",
      "amount_cad          0.0\n",
      "debit_credit        0.0\n",
      "transaction_date    0.0\n",
      "transaction_time    0.0\n",
      "dtype: float64\n",
      "customer_id         0.000000\n",
      "country             0.000000\n",
      "province            0.218210\n",
      "city                0.261027\n",
      "industry_code       0.142910\n",
      "employee_count      0.149985\n",
      "sales               0.109997\n",
      "established_date    0.149985\n",
      "onboard_date        0.159951\n",
      "dtype: float64\n",
      "wire_id             0.0\n",
      "customer_id         0.0\n",
      "amount_cad          0.0\n",
      "debit_credit        0.0\n",
      "transaction_date    0.0\n",
      "transaction_time    0.0\n",
      "dtype: float64\n",
      "industry_code    0.0\n",
      "industry         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def replace_other_with_null(dataset):\n",
    "    dataset = dataset.replace('other', np.nan)  # Replace 'other' with NaN\n",
    "    return dataset\n",
    "# Apply the function to each dataset\n",
    "data_abm = replace_other_with_null(data_abm)\n",
    "data_card = replace_other_with_null(data_card)\n",
    "data_kyc = replace_other_with_null(data_kyc)\n",
    "data_kyc_industry_codes = replace_other_with_null(data_kyc_industry_codes)\n",
    "data_emt = replace_other_with_null(data_emt)\n",
    "data_wire = replace_other_with_null(data_wire)\n",
    "data_eft = replace_other_with_null(data_eft)\n",
    "\n",
    "print(data_abm.isnull().sum()/len(data_abm))\n",
    "print(data_card.isnull().sum()/len(data_card))\n",
    "print(data_eft.isnull().sum()/len(data_eft))\n",
    "print(data_emt.isnull().sum()/len(data_emt))\n",
    "print(data_kyc.isnull().sum()/len(data_kyc))\n",
    "print(data_wire.isnull().sum()/len(data_wire))\n",
    "print(data_kyc_industry_codes.isnull().sum()/len(data_kyc_industry_codes))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that the count for the null value for the city is relatively small, we decided to drop all rows where 'city' entry is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing data_abm...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_823/2081587740.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;31m# Function to encode categorical columns and perform multiple imputation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimpute_missing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_impute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Convert categorical columns to numerical using category codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdata_for_imputing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_823/2081587740.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(dataset, columns_to_impute)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimpute_missing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_impute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Convert categorical columns to numerical using category codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_for_imputing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdataset_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_for_imputing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_impute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_to_impute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdataset_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure NaN for missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/train_network/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'cat'"
     ]
    }
   ],
   "source": [
    "# Function to encode categorical columns and perform multiple imputation\n",
    "def impute_missing_values(dataset, columns_to_impute):\n",
    "    # Convert categorical columns to numerical using category codes\n",
    "    data_for_imputing = dataset.copy()\n",
    "    dataset_categorical ={} \n",
    "    for column in columns_to_impute:\n",
    "        dataset_categorical[column] = data_for_imputing[column].astype('category').cat\n",
    "        dataset[column] =dataset_categorical.codes\n",
    "        dataset[column].replace(-1, np.nan, inplace=True)  # Ensure NaN for missing values\n",
    "\n",
    "    # Initialize the kernel for miceforest\n",
    "    kernel = mf.ImputationKernel(\n",
    "        dataset[columns_to_impute],\n",
    "        save_all_iterations=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform multiple imputations\n",
    "    kernel.mice(5)  # Perform 5 multiple imputation iterations\n",
    "    imputed_data = kernel.complete_data(dataset=0)\n",
    "    # Convert numerical encodings back to original categories\n",
    "    for column in columns_to_impute:\n",
    "        # Ensure the column is treated as categorical\n",
    "        dataset[column] = pd.Categorical.from_codes(\n",
    "            codes=imputed_data[column].round().astype(int),  # Ensure integer codes\n",
    "            categories=dataset_categorical.categories  # Use original categories\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Specify columns to impute\n",
    "columns_to_impute = ['city', 'province', 'country']\n",
    "\n",
    "# Perform imputation on each dataset\n",
    "print(\"Imputing data_abm...\")\n",
    "data_abm_imputed = impute_missing_values(data_abm, columns_to_impute)\n",
    "\n",
    "print(\"Imputing data_card...\")\n",
    "data_card_imputed = impute_missing_values(data_card, columns_to_impute)\n",
    "\n",
    "print(\"Imputing data_kyc...\")\n",
    "data_kyc_imputed = impute_missing_values(data_kyc, columns_to_impute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 abm_id       customer_id  amount_cad debit_credit  \\\n",
      "0  ABM00000000000000006  SYNCID0000000014       25.41       credit   \n",
      "1  ABM00000000000000008  SYNCID0000000034      238.17        debit   \n",
      "2  ABM00000000000000009  SYNCID0000000034     1655.43       credit   \n",
      "3  ABM00000000000000010  SYNCID0000000034      620.69       credit   \n",
      "4  ABM00000000000000011  SYNCID0000000034      323.70        debit   \n",
      "\n",
      "   cash_indicator country province  city transaction_date transaction_time  \n",
      "0           False     0.0      7.0  50.0       2022-11-16         17:37:41  \n",
      "1            True     0.0      5.0  63.0       2022-11-18         10:22:59  \n",
      "2           False     0.0      0.0  18.0       2022-12-29         11:56:08  \n",
      "3            True     0.0      0.0  10.0       2023-01-22         16:48:12  \n",
      "4            True     0.0      5.0  74.0       2022-11-14         13:24:45  \n"
     ]
    }
   ],
   "source": [
    "print(data_abm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
